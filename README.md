# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

#### Name: SHYAM S
#### Reg.No: 212223240156
## Aim:
To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

## AI Tools Required: 
ChatGPT (or any Generative AI tool supporting LLMs)

Text editor/Word processor for documentation

Spreadsheet/Tabular tool for comparison

## Explanation: 
Define the Two Prompt Types:

Naïve Prompt: Broad, vague, or unstructured prompt without much context.

Basic Prompt: Clear, detailed, and structured prompt that provides context and specific instructions.

Experiment Steps:

Prepare multiple test scenarios such as:

Creative story generation

Answering a factual question

Summarizing an article or concept

Giving advice/recommendations

Explaining a technical concept

For each scenario, create two prompts: one naïve and one basic.

Run both prompts with ChatGPT and record outputs.

Compare the results based on Quality, Accuracy, and Depth.


## OUTPUT
| Scenario              | Naïve Prompt Output                         | Basic Prompt Output                                      | Analysis (Quality, Accuracy, Depth)                 |
| --------------------- | ------------------------------------------- | -------------------------------------------------------- | --------------------------------------------------- |
| Creative Story        | Very short, imaginative but lacks structure | Well-developed plot with characters, setting, and ending | Basic prompt produced a richer, more coherent story |
| Factual Question      | Gave a brief, somewhat correct response     | Provided accurate, detailed, and sourced explanation     | Basic prompt improved accuracy and completeness     |
| Article Summarization | Very short, missing important details       | Clear, concise summary covering main points              | Basic prompt offered better depth and clarity       |
| Advice/Recommendation | General, vague suggestions                  | Actionable, step-by-step recommendations with reasoning  | Basic prompt improved usefulness and practicality   |
| Technical Explanation | Surface-level definition without examples   | Detailed explanation with examples and applications      | Basic prompt improved depth and user understanding  |


### Analysis

Naïve prompts often resulted in vague, generic, and shallow responses.

Basic prompts consistently improved quality, accuracy, and depth of ChatGPT’s outputs.

For creative tasks, naïve prompts sometimes produced acceptable results, but structured prompts enhanced flow and richness.

For factual, summarization, advice, and technical explanations, structured prompts were crucial to achieve accurate and useful answers.

Prompt clarity directly influences the usability and reliability of AI outputs.

### Summary of Findings

Prompt clarity has a strong impact on the final output.

Basic (structured) prompts outperform naïve prompts in almost all cases.

For factual and technical tasks, structured prompts ensure precision and depth.

For creative tasks, naïve prompts can still give acceptable results, but structured prompts make them more engaging and complete.

Using structured prompts helps reduce ambiguity and ensures better control over the AI’s response.

## RESULT:
The prompt for the above said problem executed successfully
